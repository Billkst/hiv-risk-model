"""
å¯¹æ¯”ä¸åŒæ•°æ®é›†çš„æ¨¡å‹æ€§èƒ½
çœŸå®æ•°æ® vs åˆæˆæ•°æ® vs æ··åˆæ•°æ®
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')


def evaluate_dataset(csv_path, dataset_name):
    """è¯„ä¼°å•ä¸ªæ•°æ®é›†"""
    print("\n" + "=" * 80)
    print(f"è¯„ä¼°æ•°æ®é›†: {dataset_name}")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv(csv_path)
    print(f"âœ“ æ•°æ®åŠ è½½: {df.shape}")
    
    # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
    X = df.drop(columns=['æŒ‰æ–¹æ¡ˆè¯„å®šçº§åˆ«']).values
    y = df['æŒ‰æ–¹æ¡ˆè¯„å®šçº§åˆ«'].values
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # æ˜¾ç¤ºç›®æ ‡å˜é‡åˆ†å¸ƒ
    print(f"\nç›®æ ‡å˜é‡åˆ†å¸ƒ:")
    for level in sorted(np.unique(y)):
        count = (y == level).sum()
        pct = count / len(y) * 100
        print(f"  ç­‰çº§ {int(level)}: {count} æ ·æœ¬ ({pct:.1f}%)")
    
    # åˆ›å»ºæ¨¡å‹
    model = GradientBoostingClassifier(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
    
    # äº¤å‰éªŒè¯
    print(f"\nè¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯...")
    cv = KFold(n_splits=5, shuffle=True, random_state=42)
    
    scores = cross_val_score(
        model, X_scaled, y,
        cv=cv,
        scoring='f1_weighted',
        n_jobs=-1
    )
    
    # ç»“æœ
    mean_score = scores.mean()
    std_score = scores.std()
    
    print(f"\näº¤å‰éªŒè¯ç»“æœ:")
    print(f"  F1åˆ†æ•°: {mean_score:.4f} Â±{std_score:.4f}")
    print(f"  å„æŠ˜åˆ†æ•°: {[f'{s:.4f}' for s in scores]}")
    
    return {
        'dataset': dataset_name,
        'n_samples': len(X),
        'n_features': X.shape[1],
        'f1_mean': mean_score,
        'f1_std': std_score,
        'scores': scores
    }


def compare_all_datasets():
    """å¯¹æ¯”æ‰€æœ‰æ•°æ®é›†"""
    print("\n" + "=" * 80)
    print("æ•°æ®é›†æ€§èƒ½å¯¹æ¯”")
    print("=" * 80)
    
    datasets = {
        'çœŸå®æ•°æ®(190æ ·æœ¬)': 'data/processed/hiv_data_processed.csv',
        'çº¯åˆæˆæ•°æ®(500æ ·æœ¬)': 'data/processed/hiv_synthetic_data.csv',
        'æ··åˆæ•°æ®50-50(190æ ·æœ¬)': 'data/processed/hiv_mixed_50_50.csv',
        'æ··åˆæ•°æ®70-30(190æ ·æœ¬)': 'data/processed/hiv_mixed_70_30.csv'
    }
    
    results = []
    
    for name, path in datasets.items():
        try:
            result = evaluate_dataset(path, name)
            results.append(result)
        except Exception as e:
            print(f"\nâš ï¸  è¯„ä¼° {name} å¤±è´¥: {e}")
    
    # æ±‡æ€»å¯¹æ¯”
    print("\n" + "=" * 80)
    print("æ€§èƒ½æ±‡æ€»å¯¹æ¯”")
    print("=" * 80)
    
    print(f"\n{'æ•°æ®é›†':<30} {'æ ·æœ¬æ•°':<10} {'F1åˆ†æ•°':<20} {'æ’å':<10}")
    print("-" * 70)
    
    # æŒ‰F1åˆ†æ•°æ’åº
    results_sorted = sorted(results, key=lambda x: x['f1_mean'], reverse=True)
    
    for rank, result in enumerate(results_sorted, 1):
        dataset = result['dataset']
        n_samples = result['n_samples']
        f1_str = f"{result['f1_mean']:.4f} Â±{result['f1_std']:.4f}"
        
        print(f"{dataset:<30} {n_samples:<10} {f1_str:<20} #{rank}")
    
    # åˆ†æç»“è®º
    print("\n" + "=" * 80)
    print("åˆ†æç»“è®º")
    print("=" * 80)
    
    best_result = results_sorted[0]
    real_result = next((r for r in results if 'çœŸå®æ•°æ®' in r['dataset']), None)
    
    print(f"\nğŸ† æœ€ä½³æ•°æ®é›†: {best_result['dataset']}")
    print(f"   F1åˆ†æ•°: {best_result['f1_mean']:.4f} Â±{best_result['f1_std']:.4f}")
    
    if real_result:
        improvement = best_result['f1_mean'] - real_result['f1_mean']
        print(f"\nğŸ“Š ç›¸æ¯”çœŸå®æ•°æ®:")
        print(f"   çœŸå®æ•°æ®F1: {real_result['f1_mean']:.4f}")
        print(f"   æœ€ä½³æ•°æ®F1: {best_result['f1_mean']:.4f}")
        print(f"   æ€§èƒ½æå‡: {improvement:+.4f} ({improvement/real_result['f1_mean']*100:+.2f}%)")
        
        if improvement > 0.05:
            print(f"\nâœ“ åˆæˆæ•°æ®æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½")
            print(f"  å»ºè®®: ä½¿ç”¨ {best_result['dataset']} è¿›è¡Œæœ€ç»ˆè®­ç»ƒ")
        elif improvement > 0:
            print(f"\nâ‰ˆ åˆæˆæ•°æ®ç•¥å¾®æå‡æ¨¡å‹æ€§èƒ½")
            print(f"  å»ºè®®: å¯ä»¥ä½¿ç”¨ {best_result['dataset']}")
        else:
            print(f"\nâš ï¸  åˆæˆæ•°æ®æœªæå‡æ€§èƒ½")
            print(f"  å»ºè®®: ç»§ç»­ä½¿ç”¨çœŸå®æ•°æ®ï¼Œæˆ–è°ƒæ•´CTGANå‚æ•°")
    
    # æ•°æ®é‡åˆ†æ
    print(f"\nğŸ“ˆ æ•°æ®é‡å½±å“:")
    synthetic_500 = next((r for r in results if 'çº¯åˆæˆæ•°æ®' in r['dataset']), None)
    
    if synthetic_500 and real_result:
        print(f"   çœŸå®æ•°æ®(190æ ·æœ¬): F1={real_result['f1_mean']:.4f}")
        print(f"   åˆæˆæ•°æ®(500æ ·æœ¬): F1={synthetic_500['f1_mean']:.4f}")
        
        if synthetic_500['f1_mean'] > real_result['f1_mean']:
            print(f"   âœ“ å¢åŠ æ•°æ®é‡æœ‰æ•ˆæå‡æ€§èƒ½")
        else:
            print(f"   âš ï¸  å•çº¯å¢åŠ åˆæˆæ•°æ®é‡æ•ˆæœæœ‰é™")
            print(f"   å»ºè®®: ä½¿ç”¨æ··åˆæ•°æ®é›†")
    
    return results_sorted


def main():
    """ä¸»æµç¨‹"""
    print("\n" + "=" * 80)
    print("æ•°æ®é›†æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    results = compare_all_datasets()
    
    print("\n" + "=" * 80)
    print("âœ“ å¯¹æ¯”åˆ†æå®Œæˆ")
    print("=" * 80)
    
    return results


if __name__ == '__main__':
    results = main()
