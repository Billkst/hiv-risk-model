"""
äº¤å‰éªŒè¯æ¨¡å—
ä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹çš„çœŸå®æ€§èƒ½
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_validate, StratifiedKFold, KFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')


class CrossValidator:
    """äº¤å‰éªŒè¯å™¨"""
    
    def __init__(self, n_splits=5):
        self.n_splits = n_splits
        self.results = {}
        
    def get_models(self):
        """è·å–æ¨¡å‹å­—å…¸"""
        models = {
            'Logistic Regression': LogisticRegression(
                max_iter=1000,
                class_weight='balanced',
                random_state=42
            ),
            'Random Forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                class_weight='balanced',
                random_state=42,
                n_jobs=-1
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42
            ),
            'SVM': SVC(
                kernel='rbf',
                class_weight='balanced',
                random_state=42
            )
        }
        return models
    
    def run_cross_validation(self, X, y, model_name, model):
        """å¯¹å•ä¸ªæ¨¡å‹è¿è¡Œäº¤å‰éªŒè¯"""
        print(f"\n{'='*60}")
        print(f"äº¤å‰éªŒè¯: {model_name}")
        print(f"{'='*60}")
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨åˆ†å±‚KæŠ˜
        min_class_count = pd.Series(y).value_counts().min()
        
        if min_class_count >= self.n_splits:
            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)
            print(f"ä½¿ç”¨åˆ†å±‚ {self.n_splits} æŠ˜äº¤å‰éªŒè¯")
        else:
            cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)
            print(f"âš ï¸  æœ€å°ç±»åˆ«æ ·æœ¬æ•° {min_class_count} < {self.n_splits}ï¼Œä½¿ç”¨æ™®é€šKæŠ˜")
        
        # å®šä¹‰è¯„åˆ†æŒ‡æ ‡
        scoring = {
            'accuracy': 'accuracy',
            'precision_weighted': 'precision_weighted',
            'recall_weighted': 'recall_weighted',
            'f1_weighted': 'f1_weighted'
        }
        
        # æ‰§è¡Œäº¤å‰éªŒè¯
        print(f"å¼€å§‹è®­ç»ƒ...")
        cv_results = cross_validate(
            model, X, y,
            cv=cv,
            scoring=scoring,
            return_train_score=True,
            n_jobs=-1
        )
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results = {}
        for metric in ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']:
            test_scores = cv_results[f'test_{metric}']
            train_scores = cv_results[f'train_{metric}']
            
            results[metric] = {
                'test_mean': test_scores.mean(),
                'test_std': test_scores.std(),
                'train_mean': train_scores.mean(),
                'train_std': train_scores.std(),
                'test_scores': test_scores
            }
        
        # æ‰“å°ç»“æœ
        print(f"\näº¤å‰éªŒè¯ç»“æœ ({self.n_splits}æŠ˜):")
        print(f"{'æŒ‡æ ‡':<20} {'è®­ç»ƒé›†å‡å€¼':<15} {'æµ‹è¯•é›†å‡å€¼':<15} {'æµ‹è¯•é›†æ ‡å‡†å·®':<15}")
        print("-" * 65)
        
        metric_names = {
            'accuracy': 'å‡†ç¡®ç‡',
            'precision_weighted': 'ç²¾ç¡®ç‡',
            'recall_weighted': 'å¬å›ç‡',
            'f1_weighted': 'F1åˆ†æ•°'
        }
        
        for metric, name in metric_names.items():
            train_mean = results[metric]['train_mean']
            test_mean = results[metric]['test_mean']
            test_std = results[metric]['test_std']
            print(f"{name:<20} {train_mean:.4f}         {test_mean:.4f}         Â±{test_std:.4f}")
        
        # æ£€æŸ¥è¿‡æ‹Ÿåˆ
        train_test_gap = results['f1_weighted']['train_mean'] - results['f1_weighted']['test_mean']
        if train_test_gap > 0.1:
            print(f"\nâš ï¸  å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ (è®­ç»ƒ-æµ‹è¯•å·®è·: {train_test_gap:.4f})")
        else:
            print(f"\nâœ“ æ¨¡å‹æ³›åŒ–è‰¯å¥½ (è®­ç»ƒ-æµ‹è¯•å·®è·: {train_test_gap:.4f})")
        
        return results
    
    def compare_all_models(self, X, y):
        """æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹çš„äº¤å‰éªŒè¯ç»“æœ"""
        print("\n" + "=" * 80)
        print("æ‰€æœ‰æ¨¡å‹äº¤å‰éªŒè¯å¯¹æ¯”")
        print("=" * 80)
        
        models = self.get_models()
        all_results = {}
        
        for model_name, model in models.items():
            results = self.run_cross_validation(X, y, model_name, model)
            all_results[model_name] = results
        
        # æ±‡æ€»å¯¹æ¯”
        print("\n" + "=" * 80)
        print("æ¨¡å‹æ€§èƒ½æ±‡æ€»å¯¹æ¯”")
        print("=" * 80)
        
        comparison_data = []
        for model_name, results in all_results.items():
            comparison_data.append({
                'æ¨¡å‹': model_name,
                'å‡†ç¡®ç‡': f"{results['accuracy']['test_mean']:.4f}Â±{results['accuracy']['test_std']:.4f}",
                'ç²¾ç¡®ç‡': f"{results['precision_weighted']['test_mean']:.4f}Â±{results['precision_weighted']['test_std']:.4f}",
                'å¬å›ç‡': f"{results['recall_weighted']['test_mean']:.4f}Â±{results['recall_weighted']['test_std']:.4f}",
                'F1åˆ†æ•°': f"{results['f1_weighted']['test_mean']:.4f}Â±{results['f1_weighted']['test_std']:.4f}"
            })
        
        df_comparison = pd.DataFrame(comparison_data)
        print(df_comparison.to_string(index=False))
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = max(all_results.items(), 
                        key=lambda x: x[1]['f1_weighted']['test_mean'])
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]}")
        print(f"   F1åˆ†æ•°: {best_model[1]['f1_weighted']['test_mean']:.4f} Â±{best_model[1]['f1_weighted']['test_std']:.4f}")
        
        self.results = all_results
        return all_results


def test_without_infection_rate(X, y, feature_columns):
    """æµ‹è¯•ä¸ä½¿ç”¨æ„ŸæŸ“ç‡ç‰¹å¾çš„æ¨¡å‹æ€§èƒ½"""
    print("\n" + "=" * 80)
    print("å®éªŒï¼šæ’é™¤æ„ŸæŸ“ç‡ç‰¹å¾åçš„æ¨¡å‹æ€§èƒ½")
    print("=" * 80)
    
    # æ‰¾åˆ°æ„ŸæŸ“ç‡åˆ—çš„ç´¢å¼•
    if 'æ„ŸæŸ“ç‡' in feature_columns:
        infection_rate_idx = feature_columns.index('æ„ŸæŸ“ç‡')
        print(f"\næ’é™¤ç‰¹å¾: æ„ŸæŸ“ç‡ (ç¬¬ {infection_rate_idx} åˆ—)")
        
        # åˆ›å»ºä¸åŒ…å«æ„ŸæŸ“ç‡çš„ç‰¹å¾çŸ©é˜µ
        X_no_infection = np.delete(X, infection_rate_idx, axis=1)
        remaining_features = [f for f in feature_columns if f != 'æ„ŸæŸ“ç‡']
        
        print(f"å‰©ä½™ç‰¹å¾æ•°: {len(remaining_features)}")
        
        # ä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼ˆGradient Boostingï¼‰è¿›è¡Œäº¤å‰éªŒè¯
        print(f"\nä½¿ç”¨ Gradient Boosting æ¨¡å‹:")
        
        model = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42
        )
        
        validator = CrossValidator(n_splits=5)
        results = validator.run_cross_validation(X_no_infection, y, 
                                                "Gradient Boosting (æ— æ„ŸæŸ“ç‡)", model)
        
        return results, remaining_features
    else:
        print("âš ï¸  æœªæ‰¾åˆ°æ„ŸæŸ“ç‡ç‰¹å¾")
        return None, None


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("æ¨¡å‹äº¤å‰éªŒè¯ä¸æ€§èƒ½åˆ†æ")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("\næ­¥éª¤ 1: åŠ è½½æ•°æ®")
    df = pd.read_csv('data/processed/hiv_data_processed.csv')
    print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ: {df.shape}")
    
    # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
    exclude_columns = ['åŒºå¿', 'æŒ‰æ–¹æ¡ˆè¯„å®šçº§åˆ«', 'risk_level']
    feature_columns = [col for col in df.columns if col not in exclude_columns]
    
    X = df[feature_columns].values
    y = df['risk_level'].values
    
    print(f"âœ“ ç‰¹å¾æ•°: {len(feature_columns)}")
    print(f"âœ“ æ ·æœ¬æ•°: {len(X)}")
    
    # ç‰¹å¾æ ‡å‡†åŒ–
    print("\næ­¥éª¤ 2: ç‰¹å¾æ ‡å‡†åŒ–")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    print("âœ“ æ ‡å‡†åŒ–å®Œæˆ")
    
    # äº¤å‰éªŒè¯æ‰€æœ‰æ¨¡å‹
    print("\næ­¥éª¤ 3: äº¤å‰éªŒè¯æ‰€æœ‰æ¨¡å‹")
    validator = CrossValidator(n_splits=5)
    all_results = validator.compare_all_models(X_scaled, y)
    
    # æµ‹è¯•ä¸ä½¿ç”¨æ„ŸæŸ“ç‡çš„æ€§èƒ½
    print("\næ­¥éª¤ 4: æµ‹è¯•æ’é™¤æ„ŸæŸ“ç‡åçš„æ€§èƒ½")
    results_no_infection, remaining_features = test_without_infection_rate(
        X_scaled, y, feature_columns
    )
    
    print("\n" + "=" * 80)
    print("âœ“ äº¤å‰éªŒè¯åˆ†æå®Œæˆ")
    print("=" * 80)
    
    return validator, all_results, results_no_infection


if __name__ == '__main__':
    validator, all_results, results_no_infection = main()
